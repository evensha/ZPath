{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilepton analysis  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a simple dilepton analysis, quite similar to the notebook called \"Dilepton_analysis_noData.ipynb\", but with some differences. The most obvious difference is that we here also include real data. This example also has a slightly more advanced event selection.  \n",
    "\n",
    "**Notice:** This is *only an example* on how to do this. Feel free to be creative, and to find better and/or more elegant ways of doing the various steps! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <string>\n",
    "#include <stdio.h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%jsroot on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TChain *background = new TChain(\"mini\");\n",
    "TChain *data = new TChain(\"mini\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of all the background samples and their IDs can be found in **Background_samples.txt**. We read that list, and add all the samples to the TChain. We also (for later convenience) make a vector containing the dataset IDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TString sample; \n",
    "TString path; \n",
    "vector<Int_t> dataset_IDs;\n",
    "Int_t DSID;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifstream infile(\"../Input/Background_samples.txt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile.clear();\n",
    "infile.seekg(0, ios::beg);  // Start at the beginning of the file\n",
    "background->Reset(); // Reset the TChain (if necessary)  \n",
    "while(infile >> sample >> DSID){\n",
    "    path = \"http://opendata.atlas.cern/release/samples/MC/\"+sample; // Specify path to the samples \n",
    "    background->Add(path);  \n",
    "    dataset_IDs.push_back(DSID);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data->Reset(); \n",
    "data->Add(\"http://opendata.atlas.cern/release/samples/Data/DataEgamma.root\"); \n",
    "data->Add(\"http://opendata.atlas.cern/release/samples/Data/DataMuons.root\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the variables we want to include in the analysis, and link them to branches in the TTree. A few things to notice at this point: \n",
    "-  In this example we will only study events with two leptons, so the vectorial variables only need to be two dimensional. \n",
    "-  The variables are here given names corresponding to the branches in the TTree. This is not necessary, so if you want to give them other names you are free to do so. \n",
    "-  The variable called \"channelNumber\" is the same as we have called \"dataset ID\" above. These terms are used interchangeably. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int_t lep_n, lep_charge[2], lep_type[2], channelNumber; \n",
    "Float_t lep_pt[2], lep_E[2], lep_phi[2], lep_eta[2], met_et, mcWeight, jet_MV1[10]; \n",
    "Bool_t passGRL, hasGoodVertex, trigE, trigM, lep_trigMatched[2]; \n",
    "Float_t lep_etcone20[2], lep_ptcone30[2]; \n",
    "Int_t lep_flag[2]; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Float_t scaleFactor_PILEUP, scaleFactor_ELE, scaleFactor_MUON, scaleFactor_BTAG, scaleFactor_TRIGGER, scaleFactor_JVFSF, scaleFactor_ZVERTEX; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "// For MC:  \n",
    "background->SetBranchAddress(\"lep_n\",      &lep_n);\n",
    "background->SetBranchAddress(\"lep_charge\", &lep_charge);\n",
    "background->SetBranchAddress(\"lep_type\",   &lep_type);\n",
    "background->SetBranchAddress(\"lep_pt\",     &lep_pt);\n",
    "background->SetBranchAddress(\"lep_eta\",    &lep_eta);\n",
    "background->SetBranchAddress(\"lep_phi\",    &lep_phi);\n",
    "background->SetBranchAddress(\"lep_E\",      &lep_E);\n",
    "background->SetBranchAddress(\"met_et\",     &met_et); \n",
    "background->SetBranchAddress(\"channelNumber\", &channelNumber);\n",
    "background->SetBranchAddress(\"mcWeight\", &mcWeight); \n",
    "background->SetBranchAddress(\"scaleFactor_PILEUP\", &scaleFactor_PILEUP ); \n",
    "background->SetBranchAddress(\"scaleFactor_ELE\", &scaleFactor_ELE ); \n",
    "background->SetBranchAddress(\"scaleFactor_MUON\", &scaleFactor_MUON ); \n",
    "background->SetBranchAddress(\"scaleFactor_BTAG\", &scaleFactor_BTAG ); \n",
    "background->SetBranchAddress(\"scaleFactor_TRIGGER\", &scaleFactor_TRIGGER ); \n",
    "background->SetBranchAddress(\"scaleFactor_JVFSF\", &scaleFactor_JVFSF ); \n",
    "background->SetBranchAddress(\"scaleFactor_ZVERTEX\", &scaleFactor_ZVERTEX ); \n",
    "background->SetBranchAddress(\"lep_flag\", &lep_flag); \n",
    "background->SetBranchAddress(\"lep_ptcone30\", &lep_ptcone30); \n",
    "background->SetBranchAddress(\"lep_etcone20\", &lep_etcone20); \n",
    "background->SetBranchAddress(\"passGRL\", &passGRL); \n",
    "background->SetBranchAddress(\"hasGoodVertex\", &hasGoodVertex); \n",
    "background->SetBranchAddress(\"trigE\", &trigE); \n",
    "background->SetBranchAddress(\"trigM\", &trigM); \n",
    "background->SetBranchAddress(\"jet_MV1\", &jet_MV1); \n",
    "\n",
    "// For data \n",
    "data->SetBranchAddress(\"lep_n\",      &lep_n);\n",
    "data->SetBranchAddress(\"lep_charge\", &lep_charge);\n",
    "data->SetBranchAddress(\"lep_type\",   &lep_type);\n",
    "data->SetBranchAddress(\"lep_pt\",     &lep_pt);\n",
    "data->SetBranchAddress(\"lep_eta\",    &lep_eta);\n",
    "data->SetBranchAddress(\"lep_phi\",    &lep_phi);\n",
    "data->SetBranchAddress(\"lep_E\",      &lep_E);\n",
    "data->SetBranchAddress(\"met_et\",     &met_et); \n",
    "data->SetBranchAddress(\"channelNumber\", &channelNumber);\n",
    "data->SetBranchAddress(\"passGRL\", &passGRL); \n",
    "data->SetBranchAddress(\"hasGoodVertex\", &hasGoodVertex); \n",
    "data->SetBranchAddress(\"trigE\", &trigE); \n",
    "data->SetBranchAddress(\"trigM\", &trigM); \n",
    "data->SetBranchAddress(\"lep_trigMatched\", &lep_trigMatched); \n",
    "data->SetBranchAddress(\"lep_flag\", &lep_flag); \n",
    "data->SetBranchAddress(\"lep_ptcone30\", &lep_ptcone30); \n",
    "data->SetBranchAddress(\"lep_etcone20\", &lep_etcone20); \n",
    "data->SetBranchAddress(\"jet_MV1\", &jet_MV1); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Making (a lot of) histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have read our dataset we want to start analyzing the data. To do so we need to put the data into histograms. For reasons that will become clear later in the analysis we must (for each variable) make one histogram per dataset ID. (We have 31 background samples, so if we want to study 10 variables we have to make 310 histograms!) A very elegant way of dealing with all these histograms is by using [map](http://www.cplusplus.com/reference/map/map/)s (the C$++$ equivalent of Python dictionaries). Below we define one map for each variable. Here the *key values* are the dataset IDs, while the *mapped values* are the histograms.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "map<Int_t, TH1*> hist_mll; \n",
    "map<Int_t, TH1*> hist_lep_pt; \n",
    "map<Int_t, TH1*> hist_met;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(const auto & i:dataset_IDs){\n",
    "    hist_mll[i] = new TH1F(); \n",
    "    hist_lep_pt[i] = new TH1F(); \n",
    "    hist_met[i] = new TH1F();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(const auto & i:dataset_IDs){\n",
    "    hist_mll[i]->SetNameTitle(\"hist_mll\", \"Invariant mass\"); \n",
    "    hist_lep_pt[i]->SetNameTitle(\"hist_lep_pt\", \"Lepton pT\"); \n",
    "    hist_met[i]->SetNameTitle(\"hist_met\", \"Missing ET\");\n",
    "    hist_mll[i]->SetBins(20,0,500); \n",
    "    hist_lep_pt[i]->SetBins(20,0,1000);\n",
    "    hist_met[i]->SetBins(20,0,500); \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data it is only necessary with one histogram for each variable: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mll_d = new TH1F(); \n",
    "hist_lep_pt_d = new TH1F(); \n",
    "hist_met_d = new TH1F(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mll_d->SetNameTitle(\"hist_mll\", \"Invariant mass\"); \n",
    "hist_lep_pt_d->SetNameTitle(\"hist_lep_pt\", \"Lepton pT\"); \n",
    "hist_met_d->SetNameTitle(\"hist_met\", \"Missing ET\");\n",
    "hist_mll_d->SetBins(20,0,500); \n",
    "hist_lep_pt_d->SetBins(20,0,1000);\n",
    "hist_met_d->SetBins(20,0,500); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Fill the histograms \n",
    "We can now loop over all events in our dataset, implement desired cuts, and fill the histograms we created above. In this example we choose only events containing exactly to same flavour leptons with opposite charge (i.e. $e^+e^-$ or $\\mu^+\\mu^-$). \n",
    "Before starting the loop we extract the total number of entries (events) in the TChain. We also make [TLorentzVector](https://root.cern.ch/doc/master/classTLorentzVector.html)s, which are very practical for handling the kinematics of the leptons, e.g. calculating the invariant mass of the two leptons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "int nentries_MC = (Int_t)background->GetEntries();\n",
    "int nentries_data = (Int_t)data->GetEntries(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLorentzVector l1, l2, dileptons; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(const auto & i:dataset_IDs){ // Reset histograms if you have filled them before \n",
    "    hist_mll[i]->Reset(); \n",
    "    hist_lep_pt[i]->Reset(); \n",
    "    hist_met[i]->Reset();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mll_d->Reset(); \n",
    "hist_lep_pt_d->Reset(); \n",
    "hist_met_d->Reset(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TChain *dataset = new TChain(\"mini\"); \n",
    "int isData; \n",
    "int nentries; \n",
    "Float_t W; \n",
    "int n_bjets; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running over data...\n",
      "1 million events processed\n",
      "2 million events processed\n",
      "3 million events processed\n",
      "4 million events processed\n",
      "5 million events processed\n",
      "6 million events processed\n",
      "7 million events processed\n",
      "8 million events processed\n",
      "9 million events processed\n",
      "10 million events processed\n",
      "11 million events processed\n",
      "12 million events processed\n",
      "13 million events processed\n",
      "14 million events processed\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for(isData = 1; isData<2; isData++){\n",
    "\n",
    "    if(isData == 1){ \n",
    "        nentries = nentries_data; \n",
    "        dataset = data; \n",
    "        cout << \"Running over data...\" << endl; \n",
    "    }\n",
    "    else {\n",
    "        nentries = nentries_MC;\n",
    "        dataset = background;     \n",
    "        cout << \"Running over background...\" << endl; \n",
    "    }\n",
    "\n",
    "    for (int i = 0; i < nentries; i++){\n",
    "\n",
    "        if( i%1000000 == 0 && i>0){ cout << i/1000000 << \" million events processed\" << endl;}\n",
    "        dataset->GetEntry(i); // We \"pull out\" the i'th entry in the chain. The variables are now \n",
    "                              // available through the names we have given them. \n",
    "\n",
    "        // Data quality cuts: \n",
    "\n",
    "        if(passGRL == 0){ continue; } \n",
    "        if(hasGoodVertex == 0){ continue; }\n",
    "        //if(trigM == 0 && trigE == 0){ continue; } \n",
    "\n",
    "        // Require \"good leptons\": \n",
    "\n",
    "        if( lep_pt[0]/1000.0 < 25 ){ continue; }\n",
    "        if( lep_etcone20[0]/lep_pt[0] > 0.15 ){ continue; }\n",
    "        if( lep_ptcone30[0]/lep_pt[0] > 0.15 ){ continue; }\n",
    "        if( !(lep_flag[0] & 512) ){ continue; }\n",
    "\n",
    "        if( lep_pt[1]/1000.0 < 25 ){ continue; }\n",
    "        if( lep_etcone20[1]/lep_pt[1] > 0.15 ){ continue; }\n",
    "        if( lep_ptcone30[1]/lep_pt[1] > 0.15 ){ continue; }\n",
    "        if( !(lep_flag[1] & 512) ){ continue; }\n",
    "\n",
    "        // Event selection: \n",
    "\n",
    "        // Cut #1: Require (exactly) 2 leptons\n",
    "        if(lep_n != 2){ continue; }\n",
    "        // Cut #2: Require opposite charge\n",
    "        if(lep_charge[0] == lep_charge[1]){ continue; }\n",
    "        // Cut #3: Require same flavour (2 electrons or 2 muons)\n",
    "        if(lep_type[0] != lep_type[1]){ continue; }\n",
    "\n",
    "        // Set Lorentz vectors: \n",
    "        l1.SetPtEtaPhiE(lep_pt[0]/1000., lep_eta[0], lep_phi[0], lep_E[0]/1000.);\n",
    "        l2.SetPtEtaPhiE(lep_pt[1]/1000., lep_eta[1], lep_phi[1], lep_E[1]/1000.);\n",
    "        // Variables are stored in the TTree with unit MeV, so we need to divide by 1000 \n",
    "        // to get GeV, which is a more practical and commonly used unit. \n",
    "\n",
    "        dileptons = l1 + l2;       \n",
    "\n",
    "        if(isData == 1){\n",
    "            hist_mll_d->Fill(dileptons.M());\n",
    "            hist_lep_pt_d->Fill(l1.Pt());\n",
    "            hist_lep_pt_d->Fill(l2.Pt()); \n",
    "            hist_met_d->Fill(met_et/1000);                       \n",
    "        }\n",
    "        else{    \n",
    "            W = mcWeight*scaleFactor_PILEUP*scaleFactor_ELE*scaleFactor_MUON*scaleFactor_BTAG*scaleFactor_TRIGGER*scaleFactor_JVFSF*scaleFactor_ZVERTEX; \n",
    "            hist_mll[channelNumber]->Fill(dileptons.M(), W);\n",
    "            hist_lep_pt[channelNumber]->Fill(l1.Pt(), W);\n",
    "            hist_lep_pt[channelNumber]->Fill(l2.Pt(), W); \n",
    "            hist_met[channelNumber]->Fill(met_et/1000, W);   \n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "}    \n",
    "cout << \"Done!\" << endl; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now done the \"heavy lifting\" of an analysis, i.e. looping through all the events. Usually in such an analysis we create new ROOT files where we store the histograms we made above, and then analyse the output in a separate program/script. The advantage of doing this is that you can do the rest of the analysis in another language, e.g. Python, since we are done with part that requires the speed of C$++$. If you want to write ROOT files you can check out the [TFile](https://root.cern.ch/doc/master/classTFile.html) class reference. In this example we will however carry on in C$++$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scale and classify the histograms (MC only) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we are ready to make plots we need to do some further processing of the histograms we made above. The information necessary for doing the two steps below is found in the file **Infofile.txt**.   \n",
    "1. We need to **scale** the histograms to the right cross section and luminosity. Why? When making the MC samples a certain number of events is simulated, which will usually not correspond to the number of events in our data. The expected number of events from a certain kind of process is given by $N=\\sigma L$, where $\\sigma$ is the cross section and $L$ is the integrated luminosity. Therefore we need to scale each histogram by a scale factor <br> <br>\n",
    "$$sf = \\frac{N}{N_{MC}} = \\frac{ \\sigma L }{N_{MC}},$$ <br>  where $N_{MC}$ is the number of generated MC events.  <br> <br>\n",
    "2. We also need to **classify** the background processes into different categories. This is necessary when we eventually want to make the characteristic colorful background plots you might have seen before.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Make new histograms \n",
    "Maybe a bit depressingly we have to make a set of new histograms, this time corresponding to the different background categories, instead of the dataset IDs. Notice that these new histograms are made in a very similar way as above, i.e. with the same range and binning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFile *MyFile = new TFile(\"test.root\", \"NEW\"); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mll[147770]->Write(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyFile->Close(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TString S; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TString myFile; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TString OutputPath; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = to_string(147770); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFile file(\"Output/TEST.root\", \"RECREATE\"); \n",
    "hist_lep_pt[147770]->Write(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//for( const auto id:dataset_IDs){\n",
    "    S = to_string(147770);\n",
    "    OutputPath = \"Output/\"+S+\".root\"; \n",
    "    TFile *ofile = new TFile(OutputPath, \"NEW\");\n",
    "    hist_mll[147770]->Write(); \n",
    "//}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map<TString, TH1*> H_mll; \n",
    "map<TString, TH1*> H_lep_pt; \n",
    "map<TString, TH1*> H_met;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector<TString> Backgrounds; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Backgrounds = {\"Higgs\",\"Diboson\", \"Wjets\", \"DY\", \"singleTop\", \"ttbar\", \"Zjets\"}; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(const auto i:Backgrounds){\n",
    "    H_mll[i] = new TH1F(); \n",
    "    H_lep_pt[i] = new TH1F(); \n",
    "    H_met[i] = new TH1F(); \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(const auto & i:Backgrounds){\n",
    "    H_mll[i]->SetNameTitle(\"hist_mll\", \"Invariant mass\"); \n",
    "    H_lep_pt[i]->SetNameTitle(\"hist_lep_pt\", \"Lepton pT\"); \n",
    "    H_met[i]->SetNameTitle(\"hist_met\", \"Missing ET\");\n",
    "    H_mll[i]->SetBins(20,0,500); \n",
    "    H_lep_pt[i]->SetBins(20,0,1000);\n",
    "    H_met[i]->SetBins(20,0,500); \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Scale and add histograms \n",
    "Now we read our info file, scale all (old) histograms, and then add them to the new histograms we just defined.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifstream info(\"Infofile.txt\"); \n",
    "TString process; \n",
    "TString type; \n",
    "Int_t dsid; \n",
    "Int_t n_events; \n",
    "Double_t red_eff; \n",
    "Double_t sum_w; \n",
    "Double_t x_sec; \n",
    "Double_t L; // Integrated luminosity (pb)\n",
    "Double_t SF; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 1000.6; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(const auto & i:Backgrounds){\n",
    "    H_mll[i]->Reset(); \n",
    "    H_lep_pt[i]->Reset(); \n",
    "    H_met[i]->Reset();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.clear();\n",
    "info.seekg(0, ios::beg);  \n",
    "while(info >> process >> type >> dsid >> n_events >> red_eff >> sum_w >> x_sec){\n",
    "    \n",
    "    SF = x_sec*L/(sum_w*red_eff); \n",
    "\n",
    "    hist_mll[dsid]->Scale(SF); \n",
    "    hist_lep_pt[dsid]->Scale(SF); \n",
    "    hist_met[dsid]->Scale(SF); \n",
    "    \n",
    "    H_mll[type]->Add(hist_mll[dsid]); \n",
    "    H_lep_pt[type]->Add(hist_lep_pt[dsid]); \n",
    "    H_met[type]->Add(hist_met[dsid]); \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Color the histograms \n",
    "Make yet another map, this time containing the colors you want the backgrounds to have, and then set the colors of your histograms. Note that colors are defined by integers in ROOT. If you are not happy with the colors chosen below you can have look at the [TColor](https://root.cern.ch/doc/master/classTColor.html) class reference for more options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map<TString, Int_t> colors; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors[\"Diboson\"] = kGreen; \n",
    "colors[\"Zjets\"] = kYellow; \n",
    "colors[\"ttbar\"] = kRed;\n",
    "colors[\"singleTop\"] = kBlue-7; \n",
    "colors[\"Wjets\"] = kBlue+3; \n",
    "colors[\"DY\"] = kOrange+1; \n",
    "colors[\"Higgs\"] = kMagenta; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(const auto h:Backgrounds){\n",
    "    H_mll[h]->SetFillColor(colors[h]); \n",
    "    H_met[h]->SetFillColor(colors[h]);\n",
    "    H_lep_pt[h]->SetFillColor(colors[h]);\n",
    "    \n",
    "    H_mll[h]->SetLineColor(colors[h]); \n",
    "    H_met[h]->SetLineColor(colors[h]);\n",
    "    H_lep_pt[h]->SetLineColor(colors[h]);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stack and plot the histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have arrived to the part where we can plot the results of all the work done above. For each variable we need to stack the backgrounds on top of each other, which is done by using the [THStack](https://root.cern.ch/doc/master/classTHStack.html) class. In the example below we do this for two variables; invariant mass and missing $E_T$.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THStack *stack_mll = new THStack(\"Invariant mass\", \"\");\n",
    "THStack *stack_met = new THStack(\"Missing ET\", \"\"); \n",
    "THStack *stack_lep_pt = new THStack(\"Lepton pT\", \"\"); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(const auto h:Backgrounds){\n",
    "    stack_mll->RecursiveRemove(H_mll[h]); // Remove previously stacked histograms  \n",
    "    stack_met->RecursiveRemove(H_met[h]);\n",
    "    stack_lep_pt->RecursiveRemove(H_lep_pt[h]);\n",
    "    stack_mll->Add(H_mll[h]); \n",
    "    stack_met->Add(H_met[h]);\n",
    "    stack_lep_pt->Add(H_lep_pt[h]); \n",
    "}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make a legend (see [TLegend](https://root.cern.ch/doc/master/classTLegend.html)), and add  the different backgrounds. Next we make a canvas (see [TCanvas](https://root.cern.ch/doc/master/classTCanvas.html)), which is allways necessary when we want to make a plot. Then you draw the stack and the legend, and display them by drawing the canvas. We can also specify axis labels and a bunch of other stuff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gStyle->SetLegendBorderSize(0); // Remove (default) border around legend \n",
    "TLegend *leg = new TLegend(0.65, 0.60, 0.9, 0.85); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg->Clear();\n",
    "for(const auto i:Backgrounds){\n",
    "    leg->AddEntry(H_mll[i], i, \"f\");  // Add your histograms to the legend\n",
    "} \n",
    "leg->AddEntry(hist_mll_d, \"Data\", \"lep\"); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCanvas *C = new TCanvas(\"c\", \"c\", 600, 600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gPad->SetLogy(); // Set logarithmic y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mll_d->SetLineColor(kBlack); \n",
    "hist_mll_d->SetMarkerStyle(kFullCircle); \n",
    "hist_mll_d->SetMarkerColor(kBlack); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_mll->Draw(\"hist\"); \n",
    "stack_mll->SetMaximum(1E6); \n",
    "stack_mll->GetYaxis()->SetTitle(\"# events\");\n",
    "stack_mll->GetYaxis()->SetTitleOffset(1.3); \n",
    "stack_mll->GetXaxis()->SetTitle(\"m_{ll} (GeV)\");\n",
    "stack_mll->GetXaxis()->SetTitleOffset(1.3);\n",
    "hist_mll_d->Draw(\"same E\"); \n",
    "leg->Draw();\n",
    "C->Draw();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_met_d->SetLineColor(kBlack); \n",
    "hist_met_d->SetMarkerStyle(kFullCircle); \n",
    "hist_met_d->SetMarkerColor(kBlack); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stack_met->Draw(\"hist\"); \n",
    "stack_met->SetMaximum(1E6); \n",
    "stack_met->SetMinimum(1E-2); \n",
    "stack_met->GetYaxis()->SetTitle(\"# events\");\n",
    "stack_met->GetYaxis()->SetTitleOffset(1.3); \n",
    "stack_met->GetXaxis()->SetTitle(\"E_{T}^{miss} (GeV)\");\n",
    "stack_met->GetXaxis()->SetTitleOffset(1.3);\n",
    "hist_met_d->Draw(\"same e\"); \n",
    "leg->Draw();\n",
    "C->Draw(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_lep_pt_d->SetLineColor(kBlack); \n",
    "hist_lep_pt_d->SetMarkerStyle(kFullCircle); \n",
    "hist_lep_pt_d->SetMarkerColor(kBlack); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stack_lep_pt->Draw(\"hist\"); \n",
    "stack_lep_pt->SetMaximum(1E6); \n",
    "stack_lep_pt->GetYaxis()->SetTitle(\"# events\");\n",
    "stack_lep_pt->GetYaxis()->SetTitleOffset(1.3); \n",
    "stack_lep_pt->GetXaxis()->SetTitle(\"p_{T} (GeV)\");\n",
    "stack_lep_pt->GetXaxis()->SetTitleOffset(1.3);\n",
    "hist_lep_pt_d->Draw(\"same e\"); \n",
    "leg->Draw();\n",
    "C->Draw(); "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT C++",
   "language": "c++",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".C",
   "mimetype": " text/x-c++src",
   "name": "c++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
